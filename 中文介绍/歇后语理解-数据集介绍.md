## 歇后语理解数据集


## Two-Part Allegorical Saying Comprehension Dataset  


### 数据描述：
歇后语理解数据集采用标准化选择题形式：
一、上下句对应关系选择题
题目呈现完整的歇后语结构要素：
上句推导下句：给出歇后语的前半部分（比喻性描述），要求从选项中选出逻辑匹配的后半部分（解释性语义），例如根据 "孔夫子搬家" 选择正确的下半句 "净是书（输）"，干扰项可能包含同音字误解或语义相关但不精准的表达。
下句反推上句：提供歇后语的后半部分，要求逆向匹配对应的前半部分，重点考查对歇后语固定搭配的记忆准确度和比喻逻辑的理解深度。该类题目通过结构化选项设计，精准测评考生对歇后语固定搭配的掌握程度及前后语义映射关系的解析能力。
二、语境应用选择题
题目构建真实语言场景，在句子关键位置嵌入歇后语空缺，要求从多个选项中选出最符合语境的歇后语。
语义契合度：判断歇后语含义是否与句子表达的核心意思一致（如在描述 "做事反复无常" 的语境中区分 "猴子掰玉米" 和 "墙头草" 的适用差异）
修辞适配性：考量歇后语的比喻、双关等修辞手段是否与语境的表达风格匹配（如书面语场景与口语化歇后语的适用性判断）
文化隐喻理解：评估考生对歇后语背后文化典故的认知（如理解 "周瑜打黄盖 —— 一个愿打一个愿挨" 需掌握三国典故背景）此类题目通过具体语境中的语义辨析，实现对歇后语实际运用能力的深度测评，涵盖从基础记忆到语境迁移的多层级能力考查。


### 适配方法：
LoRA适配
LoRA微调是指利用低秩分解来表示大模型的参数更新，从而减少微调所需的资源和时间。LORA是Low-Rank Adaptation of Large Language Models的缩写，出自论文《LoRA: Low-Rank Adaptation of Large Language Models》。LORA的基本思想是假设模型在任务适配过程中权重的改变量是低秩（low rank）的，因此可以用两个较小的矩阵来表示参数更新，同时保持预训练的权重不变。LORA可以应用于各种自然语言处理任务，如内容理解、生成任务等，实验表明LORA可以在保持或提高模型性能的同时，显著降低训练参数和推理延迟。


### 数据集构成和规范：

#### 源数据量：

训练集796条, 验证集114条, 测试集227条。

#### 评测数据量：

评测数据量为公开的测试集227条。

#### 源数据字段：

|  KEYS   | EXPLAIN  |
|  ----  | ----  |
| question  | 问题数据id |
| choices  | 含有四个选项的列表 |
| answer  | 正确答案 |


### 源数据集样例：

```
{
  "question":"____，比喻不强迫别人，而是等待愿意的人来参与或接受。",
  "choices": [
    "孔夫子搬家——尽是输(书)",
    "大水冲了龙王庙——自家人不认自家人",
    "姜太公钓鱼——愿者上钩",
    "挂羊头卖狗肉——有名无实"
  ],
  "answer":"C"
}
```


### 论文引用：

>   ```
>   @article{hu2022lora,
>     title={Lora: Low-rank adaptation of large language models.},
>     author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu and others},
>     journal={ICLR},
>     volume={1},
>     number={2},
>     pages={3},
>     year={2022}
>   }
>   ```

### 源数据集版权使用说明：

