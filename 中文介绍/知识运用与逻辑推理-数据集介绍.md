## 知识运用与逻辑推理数据集


## Knowledge Application and Logical Reasoning Dataset  


### 数据描述：
知识运用与逻辑推理数据集包括了选择、填空等多种形式，题目的推理难度为1-10分。


### 适配方法：
LoRA适配
LoRA微调是指利用低秩分解来表示大模型的参数更新，从而减少微调所需的资源和时间。LORA是Low-Rank Adaptation of Large Language Models的缩写，出自论文《LoRA: Low-Rank Adaptation of Large Language Models》。LORA的基本思想是假设模型在任务适配过程中权重的改变量是低秩（low rank）的，因此可以用两个较小的矩阵来表示参数更新，同时保持预训练的权重不变。LORA可以应用于各种自然语言处理任务，如内容理解、生成任务等，实验表明LORA可以在保持或提高模型性能的同时，显著降低训练参数和推理延迟。


### 数据集构成和规范：

#### 源数据量：

训练集1400条, 验证集200条, 测试集400条。

#### 评测数据量：

评测数据量为公开的测试集400条。

#### 源数据字段：

|  KEYS   | EXPLAIN  |
|  ----  | ----  |
| question  | 问题数据id |
| choices  | 含有四个选项的列表 |
| answer  | 正确答案 |


### 源数据集样例：

```
{
  "question":"小严、小易、小孔3人从单位脱颖而出,到市里参加竞聘。5人预测:小严、小易都入选;小严、小易至多有1人入选:小严入选,小易未入选:小严未入选,小易入选;若小严入选,则小孔也入选。结果发现,只有1人预测正确。由此可以推出（）。",
  "choices": [
    "小严、小易都未入选",
    "小易、小孔都入选",
    "小严、小孔都未入选",
    "小严、小易都入选"
  ],
  "answer":"D"
}
```


### 论文引用：

>   ```
>   @article{lugosch2019speech,
>     title={Speech model pre-training for end-to-end spoken language understanding},
>     author={Lugosch, Loren and Ravanelli, Mirco and Ignoto, Patrick and Tomar, Vikrant Singh and Bengio, Yoshua},
>     journal={arXiv preprint arXiv:1904.03670},
>     year={2019}
>   }
>   ```

### 源数据集版权使用说明：

