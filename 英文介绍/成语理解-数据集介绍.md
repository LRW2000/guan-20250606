## Idiom Comprehension Dataset

### Data Description:
The Idiom Comprehension Dataset is constructed in the form of standardized multiple - choice questions, mainly including two core question - type modules. The first type is the context - matching multiple - choice question. The question provides a complete sentence context, with an idiom - filling blank in a key position. The examinee is required to accurately select the idiom that conforms to the semantic, grammatical and logical relationships of the context from multiple options. The second type focuses on the discrimination of idiom relationships. The question lists several idioms, and the examinee is required to judge the logical associations or differential characteristics among the idioms from the dimensions of near - synonym relationships, antonym relationships, differences in emotional colors, and differences in applicable contexts.


### Adaptation Method:  
LoRA Adaptation  
LoRA fine-tuning refers to using low-rank decomposition to represent the parameter updates of large models, thereby reducing the resources and time required for fine-tuning. LoRA is the abbreviation of "Low-Rank Adaptation of Large Language Models," originating from the paper *LoRA: Low-Rank Adaptation of Large Language Models*. The basic idea of LoRA is to assume that the amount of weight change in the model during task adaptation is low-rank. Therefore, parameter updates can be represented by two smaller matrices, while keeping the pre-trained weights unchanged. LoRA can be applied to various natural language processing tasks, such as content understanding and generation tasks. Experiments show that LoRA can significantly reduce training parameters and inference latency while maintaining or improving model performance.

### Dataset Composition and Specifications:

#### Source Data Volume:
There are 700 items in the training set, 100 items in the validation set, and 200 items in the test set.

#### Evaluation Data Volume:
The evaluation data volume is the publicly available test set of 200 items.

#### Source Data Fields:
|  KEYS   | EXPLAIN  |
|  ----  | ----  |
| question  | The ID of the question data. |
| choices  | A list containing four options. |
| answer  | The correct answer. |

### Sample of the Source Dataset:

```
{
  "question": "Which of the following idioms has the least similar meaning to the other three?",
  "choices": [
    "Lead by example",
    "Flat - as - a - pancake",
    "Take the lead",
    "Set an example"
  ],
  "answer": "B"
}
```

### Paper Citation:

>   ```
>   @article{hu2022lora,
>     title={Lora: Low-rank adaptation of large language models.},
>     author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu and others},
>     journal={ICLR},
>     volume={1},
>     number={2},
>     pages={3},
>     year={2022}
>   }
>   ```

### Source Dataset Copyright Usage Notice:  
[Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License](https://fluent.ai/wp-content/uploads/2021/04/Fluent_Speech_Commands_Public_License.pdf)